{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "def parse_titration(lines, jw, nc) -> list[dict[str, Any]]:\n",
    "    tot_lenght = len(lines)\n",
    "    sections = [\n",
    "        (lambda line: line.strip(), 1, \"titration_name\"),  # NAMET\n",
    "        (\n",
    "            lambda line: [int(part) for part in line.split()],\n",
    "            1,\n",
    "            \"titration_comp_settings\",\n",
    "        ),  # JP,NCET\n",
    "        (\n",
    "            lambda line: [\n",
    "                float(part) if i != 2 else int(part)\n",
    "                for i, part in enumerate(line.split())\n",
    "            ],\n",
    "            \"NC\",\n",
    "            \"components_concentrations\",\n",
    "        ),  # CO,CTT,LOK\n",
    "        (\n",
    "            lambda line: [float(part) for _, part in enumerate(line.split())],\n",
    "            1,\n",
    "            \"background_params\",\n",
    "        ),  # COI,CTI,IREFT\n",
    "        (\n",
    "            lambda line: [float(part) for _, part in enumerate(line.split())],\n",
    "            1,\n",
    "            \"v_params\",\n",
    "        ),  # VO,SIGMAV\n",
    "        (\n",
    "            lambda line: [\n",
    "                float(part) if i < 5 else int(part)\n",
    "                for i, part in enumerate(line.split())\n",
    "            ],\n",
    "            1,\n",
    "            \"potential_params\",\n",
    "        ),  # E0,SIGMAE,JA,JB,SLOPE,LOK1,LOK2,LOK3,LOK4\n",
    "        (\n",
    "            lambda line: [\n",
    "                float(part) if i != 3 else int(part)\n",
    "                for i, part in enumerate(\n",
    "                    map(lambda x: x.replace(\"(\", \"\").replace(\")\", \"\"), line.split())\n",
    "                )\n",
    "            ],\n",
    "            \"until_end\",\n",
    "            \"titration_values\",\n",
    "        ),  # V,E,(SIGMA),IND\n",
    "    ]\n",
    "    line_counter = 0\n",
    "    titrations = []\n",
    "    while True:\n",
    "        titration = {}\n",
    "        for process_func, repeat, name in sections:\n",
    "            if isinstance(repeat, int):\n",
    "                for _ in range(repeat):\n",
    "                    titration[name] = process_func(lines[line_counter])\n",
    "                    line_counter += 1\n",
    "            elif repeat == \"NC\":\n",
    "                for _ in range(nc):\n",
    "                    parsed_line = process_func(lines[line_counter])\n",
    "                    titration.setdefault(name, []).append(parsed_line)\n",
    "                    parsed_line = {\n",
    "                        k: v\n",
    "                        for k, v in zip(\n",
    "                            [\"C0\", \"CTT\", \"LOK\"],\n",
    "                            parsed_line,\n",
    "                        )\n",
    "                    }\n",
    "                    line_counter += 1\n",
    "\n",
    "            elif repeat == \"until_end\":\n",
    "                while True:\n",
    "                    parsed_line = process_func(lines[line_counter])\n",
    "                    titration.setdefault(\"volume\", []).append(parsed_line[0])\n",
    "                    titration.setdefault(\"potential\", []).append(parsed_line[1])\n",
    "                    if jw == 2:\n",
    "                        titration.setdefault(\"sigma\", []).append(parsed_line[2])\n",
    "                    line_counter += 1\n",
    "                    if parsed_line[-1] == 1:\n",
    "                        break\n",
    "\n",
    "        titrations.append(titration)\n",
    "        if line_counter == tot_lenght:\n",
    "            break\n",
    "\n",
    "    return titrations\n",
    "\n",
    "\n",
    "def parse_model(lines, icd, nc) -> list[dict[str, Any]]:\n",
    "    species = []\n",
    "    sections = [\n",
    "        lambda line: [\n",
    "            int(part) if i > 2 else float(part)\n",
    "            for i, part in enumerate(\n",
    "                map(lambda x: x.replace(\"(\", \"\").replace(\")\", \"\"), line.split())\n",
    "            )\n",
    "        ],  # BLOG,IX(NC times),KEY,NKA,IKA(NKA times) (ICD=0)\n",
    "        lambda line: [\n",
    "            int(part) if i > 4 else float(part)\n",
    "            for i, part in enumerate(\n",
    "                map(lambda x: x.replace(\"(\", \"\").replace(\")\", \"\"), line.split())\n",
    "            )\n",
    "        ],\n",
    "        # BLOG,(IB),C,D,E,IX(1...NC),KEY,KEYC,KEYD,KEYE,NKA,IKA(1...NKA) (ICD=1/2)\n",
    "    ]\n",
    "\n",
    "    if icd == 0:\n",
    "        process_func = sections[1]\n",
    "        model_columns = (\n",
    "            [\n",
    "                \"BLOG\",\n",
    "            ]\n",
    "            + [f\"IX{i}\" for i in range(1, nc + 1)]\n",
    "            + [\n",
    "                \"KEY\",\n",
    "                \"NKA\",\n",
    "            ]\n",
    "            + [f\"IKA{i}\" for i in range(1, 10)]\n",
    "        )\n",
    "    else:\n",
    "        process_func = sections[0]\n",
    "        model_columns = (\n",
    "            [\n",
    "                \"BLOG\",\n",
    "                \"IB\",\n",
    "                \"C\",\n",
    "                \"D\",\n",
    "                \"E\",\n",
    "            ]\n",
    "            + [f\"IX{i}\" for i in range(1, nc + 1)]\n",
    "            + [\n",
    "                \"KEY\",\n",
    "                \"KEYC\",\n",
    "                \"KEYD\",\n",
    "                \"KEYE\",\n",
    "                \"NKA\",\n",
    "            ]\n",
    "            + [f\"IKA{i}\" for i in range(1, 10)]\n",
    "        )\n",
    "\n",
    "    for line in lines:\n",
    "        parsed_line = process_func(line)\n",
    "        parsed_line = {\n",
    "            k: v\n",
    "            for k, v in zip(\n",
    "                model_columns,\n",
    "                parsed_line,\n",
    "            )\n",
    "        }\n",
    "        species.append(parsed_line)\n",
    "\n",
    "    return species\n",
    "\n",
    "\n",
    "def parse_file(filename):\n",
    "    # Define the list of tuples\n",
    "    sections = [\n",
    "        (lambda line: line.strip(), 1, \"file_name\"),  # TITLE\n",
    "        (\n",
    "            lambda line: [int(part) for part in line.split()],\n",
    "            1,\n",
    "            [\"MAXIT\", \"NC\", \"NS\", \"JW\", \"ICD\", \"WESP\", \"SHLIM\"],\n",
    "        ),  # MAXIT,NC,NS,JW,ICD,WESP,SHLIM\n",
    "        (lambda line: line.strip(), \"NC\", \"comp_name\"),  # COMP\n",
    "        (\n",
    "            lambda line: [float(part) for part in line.split()],\n",
    "            1,\n",
    "            [\"TEMP\", \"PHI\", \"PHF\"],\n",
    "        ),  # TEMP,PHI,PHF\n",
    "        (\n",
    "            lambda line: [\n",
    "                float(part) if i < 9 else int(part)\n",
    "                for i, part in enumerate(line.split())\n",
    "            ],\n",
    "            \"ICD\",\n",
    "            [\"IREF\", \"AT\", \"BT\", \"c0\", \"c1\", \"d0\", \"d1\", \"e0\", \"e1\", \"KCD\"],\n",
    "        ),  # IREF,AT,BT,c0,c1,d0,d1,e0,e1,KCD(1...6)\n",
    "        (\n",
    "            lambda line: [float(part) for part in line.split()],\n",
    "            1,\n",
    "            \"charges\",\n",
    "        ),  # Z(1...NC)\n",
    "        (\n",
    "            parse_model,\n",
    "            \"NS\",\n",
    "            \"species\",\n",
    "        ),  # BLOG,(IB),C,D,E,IX(1...NC),KEY,KEYC,KEYD,KEYE,NKA,IKA(1...NKA)\n",
    "        (parse_titration, \"end_of_file\", \"titrations\"),\n",
    "    ]\n",
    "\n",
    "    with open(filename, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    result = {}\n",
    "    line_counter = 0\n",
    "\n",
    "    for process_func, repeat, name in sections:\n",
    "        if isinstance(repeat, int):\n",
    "            for _ in range(repeat):\n",
    "                if isinstance(name, str):\n",
    "                    result[name] = process_func(lines[line_counter])\n",
    "                elif isinstance(name, list):\n",
    "                    for field_name, data in zip(\n",
    "                        name, process_func(lines[line_counter])\n",
    "                    ):\n",
    "                        result[field_name] = data\n",
    "                line_counter += 1\n",
    "        elif repeat == \"NC\":\n",
    "            nc = result[\"NC\"]  # Get the value of NC from the data\n",
    "            for _ in range(nc):\n",
    "                result.setdefault(name, []).append(process_func(lines[line_counter]))\n",
    "                line_counter += 1\n",
    "        elif repeat == \"ICD\":\n",
    "            icd = result[\"ICD\"]  # Get the value of ICD from the data\n",
    "            if icd > 0:\n",
    "                for field_name, data in zip(name, process_func(lines[line_counter])):\n",
    "                    result[field_name] = data\n",
    "                line_counter += 1\n",
    "            else:\n",
    "                result[name] = []\n",
    "        elif repeat == \"NS\":\n",
    "            ns = result[\"NS\"]  # Get the value of NS from the data\n",
    "            parsed_section = process_func(\n",
    "                lines[line_counter : line_counter + ns], icd, nc\n",
    "            )\n",
    "            result[name] = parsed_section\n",
    "            line_counter += ns\n",
    "        elif repeat == \"end_of_file\":\n",
    "            parsed_section = process_func(\n",
    "                lines[line_counter:], result[\"JW\"], nc\n",
    "            )\n",
    "            result[name] = parsed_section\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libeq.parsers.bstac import parse_file\n",
    "\n",
    "with open(\"/Users/lorenzo/Coding/libeq/notebooks/Zn-EDTA\", \"r\") as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = parse_file(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'C0': 0.001944, 'CTT': 0.0, 'LOK': 0},\n",
       " {'C0': 0.001988, 'CTT': 0.0, 'LOK': 1},\n",
       " {'C0': 0.028132, 'CTT': -0.2009, 'LOK': 1}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"titrations\"][0][\"components_concentrations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your list of dictionaries\n",
    "ix_values = [[d[key] for key in d if key.startswith('IX')] for d in res[\"species\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  1,  1,  1,  2,  2,  0,  0,  0,  0,  0,  0,  1,  1,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [-1, -1, -2, -3, -4, -1, -6,  1,  2,  3,  4,  5,  6,  0,  1, -1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(ix_values).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libeq-8i_JZAyh-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
